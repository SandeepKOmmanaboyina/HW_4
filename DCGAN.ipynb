{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a83be28-09c8-423c-85b1-521be21e4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2da9188-a489-4448-95d2-f6a5596e0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7865f853f64f44a4b6c126290c39127c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "data_set = datasets.CIFAR10(root=\"./data\", download=True, transform=transforms.Compose([\n",
    "    transforms.Resize(64),transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]))\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size = 128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7534dcdd-ee50-4bcb-8524-f9c8c9ad45ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb53d4964d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "noise_dimension = 100 \n",
    "\n",
    "real_value = 1 \n",
    "\n",
    "fake_value = 0 \n",
    "\n",
    "\n",
    "rand_seed = random.randint(10, 100000)\n",
    "random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3878b01-e971-463e-83b4-7c7d026d7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_initialize(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8243dbca-3f4d-4012-ad81-9f8960bb4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, passed_input):\n",
    "        discriminator_output = self.main(passed_input)\n",
    "        return discriminator_output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc44781-ddd8-4fe7-b6a4-bf906d8c450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_dimension, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, passed_input):\n",
    "        generator_output = self.main(passed_input)\n",
    "        return generator_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f71298-b165-4cfc-8ff6-f7024260bf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)\n",
    "discriminator.apply(weights_initialize)\n",
    "generator.apply(weights_initialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a34382-2881-4830-989a-ea8a3db1b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "disriminator_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "noise = torch.randn(128, noise_dimension, 1, 1, device=device)\n",
    "gen_loss_list = []\n",
    "dis_loss_list = []\n",
    "counter = 0\n",
    "counter_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6275296-3cdc-468e-8262-c01d13abf12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][0/391] DisLoss: 0.4627 GenLoss: 3.9463 D(x): 0.7078 D(G(z)): 0.0411 / 0.0635\n",
      "[0/10][1/391] DisLoss: 0.3262 GenLoss: 3.5863 D(x): 0.8852 D(G(z)): 0.1456 / 0.0621\n",
      "[0/10][2/391] DisLoss: 0.4054 GenLoss: 3.7787 D(x): 0.8791 D(G(z)): 0.1803 / 0.0358\n",
      "[0/10][3/391] DisLoss: 0.3075 GenLoss: 4.2949 D(x): 0.9029 D(G(z)): 0.1611 / 0.0243\n",
      "[0/10][4/391] DisLoss: 0.3486 GenLoss: 3.2414 D(x): 0.8147 D(G(z)): 0.0873 / 0.0595\n",
      "[0/10][5/391] DisLoss: 0.3944 GenLoss: 3.1589 D(x): 0.8537 D(G(z)): 0.1820 / 0.0587\n",
      "[0/10][6/391] DisLoss: 0.4424 GenLoss: 3.3691 D(x): 0.8334 D(G(z)): 0.1766 / 0.0497\n",
      "[0/10][7/391] DisLoss: 0.4209 GenLoss: 3.4479 D(x): 0.8552 D(G(z)): 0.1837 / 0.0518\n",
      "[0/10][8/391] DisLoss: 0.4905 GenLoss: 2.5475 D(x): 0.7763 D(G(z)): 0.1380 / 0.1037\n",
      "[0/10][9/391] DisLoss: 0.3635 GenLoss: 3.5627 D(x): 0.9132 D(G(z)): 0.2163 / 0.0372\n",
      "[0/10][10/391] DisLoss: 0.4258 GenLoss: 3.1612 D(x): 0.8143 D(G(z)): 0.1428 / 0.0550\n",
      "[0/10][11/391] DisLoss: 0.4637 GenLoss: 2.6054 D(x): 0.7948 D(G(z)): 0.1546 / 0.0980\n",
      "[0/10][12/391] DisLoss: 0.5794 GenLoss: 4.0171 D(x): 0.8640 D(G(z)): 0.2975 / 0.0250\n",
      "[0/10][13/391] DisLoss: 0.5633 GenLoss: 2.1408 D(x): 0.6666 D(G(z)): 0.0443 / 0.1709\n",
      "[0/10][14/391] DisLoss: 0.4581 GenLoss: 4.3158 D(x): 0.9566 D(G(z)): 0.3072 / 0.0230\n",
      "[0/10][15/391] DisLoss: 0.2832 GenLoss: 3.8025 D(x): 0.8341 D(G(z)): 0.0679 / 0.0368\n",
      "[0/10][16/391] DisLoss: 0.2559 GenLoss: 3.0994 D(x): 0.8827 D(G(z)): 0.1100 / 0.0611\n",
      "[0/10][17/391] DisLoss: 0.2908 GenLoss: 3.2383 D(x): 0.8944 D(G(z)): 0.1424 / 0.0540\n",
      "[0/10][18/391] DisLoss: 0.5048 GenLoss: 2.5289 D(x): 0.7898 D(G(z)): 0.1903 / 0.1186\n",
      "[0/10][19/391] DisLoss: 0.7261 GenLoss: 5.6446 D(x): 0.9213 D(G(z)): 0.4294 / 0.0059\n",
      "[0/10][20/391] DisLoss: 2.0728 GenLoss: 0.8334 D(x): 0.2136 D(G(z)): 0.0103 / 0.5752\n",
      "[0/10][21/391] DisLoss: 1.8495 GenLoss: 6.2973 D(x): 0.9633 D(G(z)): 0.7269 / 0.0129\n",
      "[0/10][22/391] DisLoss: 2.1977 GenLoss: 2.4944 D(x): 0.2675 D(G(z)): 0.0329 / 0.1723\n",
      "[0/10][23/391] DisLoss: 0.6383 GenLoss: 2.8543 D(x): 0.9091 D(G(z)): 0.3586 / 0.1681\n",
      "[0/10][24/391] DisLoss: 0.8893 GenLoss: 4.9401 D(x): 0.8643 D(G(z)): 0.3916 / 0.0162\n",
      "[0/10][25/391] DisLoss: 0.5518 GenLoss: 3.1564 D(x): 0.6844 D(G(z)): 0.0533 / 0.0757\n",
      "[0/10][26/391] DisLoss: 0.6186 GenLoss: 2.1824 D(x): 0.7809 D(G(z)): 0.2365 / 0.1699\n",
      "[0/10][27/391] DisLoss: 0.9231 GenLoss: 4.8935 D(x): 0.8412 D(G(z)): 0.4521 / 0.0132\n",
      "[0/10][28/391] DisLoss: 1.0017 GenLoss: 2.0583 D(x): 0.4968 D(G(z)): 0.0713 / 0.1865\n",
      "[0/10][29/391] DisLoss: 0.7882 GenLoss: 3.0245 D(x): 0.7541 D(G(z)): 0.3196 / 0.0843\n",
      "[0/10][30/391] DisLoss: 0.7587 GenLoss: 4.1254 D(x): 0.7360 D(G(z)): 0.2827 / 0.0313\n",
      "[0/10][31/391] DisLoss: 0.7141 GenLoss: 2.4877 D(x): 0.6708 D(G(z)): 0.1597 / 0.1235\n",
      "[0/10][32/391] DisLoss: 0.6346 GenLoss: 4.5301 D(x): 0.8470 D(G(z)): 0.3109 / 0.0200\n",
      "[0/10][33/391] DisLoss: 0.5773 GenLoss: 2.1818 D(x): 0.6883 D(G(z)): 0.0644 / 0.1546\n",
      "[0/10][34/391] DisLoss: 0.5329 GenLoss: 4.4779 D(x): 0.9182 D(G(z)): 0.3208 / 0.0174\n",
      "[0/10][35/391] DisLoss: 0.4597 GenLoss: 3.1544 D(x): 0.7391 D(G(z)): 0.0889 / 0.0598\n",
      "[0/10][36/391] DisLoss: 0.5483 GenLoss: 3.2522 D(x): 0.8259 D(G(z)): 0.2562 / 0.0574\n",
      "[0/10][37/391] DisLoss: 0.4990 GenLoss: 3.0177 D(x): 0.7918 D(G(z)): 0.1815 / 0.0665\n",
      "[0/10][38/391] DisLoss: 0.6432 GenLoss: 2.6644 D(x): 0.7494 D(G(z)): 0.2376 / 0.0863\n",
      "[0/10][39/391] DisLoss: 0.7000 GenLoss: 3.5954 D(x): 0.7926 D(G(z)): 0.3125 / 0.0448\n",
      "[0/10][40/391] DisLoss: 0.6012 GenLoss: 2.2501 D(x): 0.7162 D(G(z)): 0.1632 / 0.1431\n",
      "[0/10][41/391] DisLoss: 0.7843 GenLoss: 4.6887 D(x): 0.8420 D(G(z)): 0.3952 / 0.0150\n",
      "[0/10][42/391] DisLoss: 0.8341 GenLoss: 1.0177 D(x): 0.5351 D(G(z)): 0.0598 / 0.4140\n",
      "[0/10][43/391] DisLoss: 2.0445 GenLoss: 7.8370 D(x): 0.9664 D(G(z)): 0.8130 / 0.0008\n",
      "[0/10][44/391] DisLoss: 2.7729 GenLoss: 3.8938 D(x): 0.1142 D(G(z)): 0.0026 / 0.0455\n",
      "[0/10][45/391] DisLoss: 0.5316 GenLoss: 1.3029 D(x): 0.7476 D(G(z)): 0.1212 / 0.3398\n",
      "[0/10][46/391] DisLoss: 1.4507 GenLoss: 5.4642 D(x): 0.9497 D(G(z)): 0.6886 / 0.0084\n",
      "[0/10][47/391] DisLoss: 1.2070 GenLoss: 3.1040 D(x): 0.4437 D(G(z)): 0.0209 / 0.0669\n",
      "[0/10][48/391] DisLoss: 0.3518 GenLoss: 1.9625 D(x): 0.8600 D(G(z)): 0.1643 / 0.1673\n",
      "[0/10][49/391] DisLoss: 0.7393 GenLoss: 4.5298 D(x): 0.9302 D(G(z)): 0.4427 / 0.0157\n",
      "[0/10][50/391] DisLoss: 0.7992 GenLoss: 2.2317 D(x): 0.5753 D(G(z)): 0.0837 / 0.1377\n",
      "[0/10][51/391] DisLoss: 0.6600 GenLoss: 3.3532 D(x): 0.8629 D(G(z)): 0.3589 / 0.0485\n",
      "[0/10][52/391] DisLoss: 0.6470 GenLoss: 2.8244 D(x): 0.7169 D(G(z)): 0.2079 / 0.0953\n",
      "[0/10][53/391] DisLoss: 0.8768 GenLoss: 2.2660 D(x): 0.6792 D(G(z)): 0.2799 / 0.1237\n",
      "[0/10][54/391] DisLoss: 0.7515 GenLoss: 3.7038 D(x): 0.7652 D(G(z)): 0.3403 / 0.0349\n",
      "[0/10][55/391] DisLoss: 0.6829 GenLoss: 2.3493 D(x): 0.6508 D(G(z)): 0.1446 / 0.1324\n",
      "[0/10][56/391] DisLoss: 0.8231 GenLoss: 5.0534 D(x): 0.8544 D(G(z)): 0.4358 / 0.0098\n",
      "[0/10][57/391] DisLoss: 1.5336 GenLoss: 0.5576 D(x): 0.3260 D(G(z)): 0.0804 / 0.5910\n",
      "[0/10][58/391] DisLoss: 1.7256 GenLoss: 8.2894 D(x): 0.9576 D(G(z)): 0.7868 / 0.0005\n",
      "[0/10][59/391] DisLoss: 2.5427 GenLoss: 3.8132 D(x): 0.1412 D(G(z)): 0.0023 / 0.0512\n",
      "[0/10][60/391] DisLoss: 0.4846 GenLoss: 2.0106 D(x): 0.8295 D(G(z)): 0.1935 / 0.1866\n",
      "[0/10][61/391] DisLoss: 0.8265 GenLoss: 5.1292 D(x): 0.9559 D(G(z)): 0.4802 / 0.0116\n",
      "[0/10][62/391] DisLoss: 0.6285 GenLoss: 3.1407 D(x): 0.6249 D(G(z)): 0.0543 / 0.0676\n",
      "[0/10][63/391] DisLoss: 0.5482 GenLoss: 2.2656 D(x): 0.7975 D(G(z)): 0.2302 / 0.1350\n",
      "[0/10][64/391] DisLoss: 0.8526 GenLoss: 3.5675 D(x): 0.7899 D(G(z)): 0.4048 / 0.0389\n",
      "[0/10][65/391] DisLoss: 0.6780 GenLoss: 2.1186 D(x): 0.6288 D(G(z)): 0.1062 / 0.1597\n",
      "[0/10][66/391] DisLoss: 0.5368 GenLoss: 3.2996 D(x): 0.8725 D(G(z)): 0.3001 / 0.0522\n",
      "[0/10][67/391] DisLoss: 0.5645 GenLoss: 2.9172 D(x): 0.7501 D(G(z)): 0.1814 / 0.0754\n",
      "[0/10][68/391] DisLoss: 0.6493 GenLoss: 2.7270 D(x): 0.7483 D(G(z)): 0.2509 / 0.0903\n",
      "[0/10][69/391] DisLoss: 0.5815 GenLoss: 2.8396 D(x): 0.7673 D(G(z)): 0.2151 / 0.0764\n",
      "[0/10][70/391] DisLoss: 0.8582 GenLoss: 3.2277 D(x): 0.7007 D(G(z)): 0.3138 / 0.0516\n",
      "[0/10][71/391] DisLoss: 0.6509 GenLoss: 3.2581 D(x): 0.7317 D(G(z)): 0.2268 / 0.0531\n",
      "[0/10][72/391] DisLoss: 0.6346 GenLoss: 3.5983 D(x): 0.7535 D(G(z)): 0.2500 / 0.0441\n",
      "[0/10][73/391] DisLoss: 0.5866 GenLoss: 2.5266 D(x): 0.7252 D(G(z)): 0.1832 / 0.0995\n",
      "[0/10][74/391] DisLoss: 0.6487 GenLoss: 4.9233 D(x): 0.8455 D(G(z)): 0.3426 / 0.0117\n",
      "[0/10][75/391] DisLoss: 0.4536 GenLoss: 2.7057 D(x): 0.7101 D(G(z)): 0.0600 / 0.0934\n",
      "[0/10][76/391] DisLoss: 0.6995 GenLoss: 4.4165 D(x): 0.8581 D(G(z)): 0.3725 / 0.0204\n",
      "[0/10][77/391] DisLoss: 0.4760 GenLoss: 2.9822 D(x): 0.7371 D(G(z)): 0.1046 / 0.0722\n",
      "[0/10][78/391] DisLoss: 0.6305 GenLoss: 5.8204 D(x): 0.8969 D(G(z)): 0.3474 / 0.0077\n",
      "[0/10][79/391] DisLoss: 0.7453 GenLoss: 3.0547 D(x): 0.6071 D(G(z)): 0.0468 / 0.0659\n",
      "[0/10][80/391] DisLoss: 0.6536 GenLoss: 5.0372 D(x): 0.8692 D(G(z)): 0.3590 / 0.0108\n",
      "[0/10][81/391] DisLoss: 0.3133 GenLoss: 4.4146 D(x): 0.8235 D(G(z)): 0.0825 / 0.0185\n",
      "[0/10][82/391] DisLoss: 0.3462 GenLoss: 2.9345 D(x): 0.8182 D(G(z)): 0.0995 / 0.0823\n",
      "[0/10][83/391] DisLoss: 0.6978 GenLoss: 6.2541 D(x): 0.9097 D(G(z)): 0.3909 / 0.0042\n",
      "[0/10][84/391] DisLoss: 0.7673 GenLoss: 3.0926 D(x): 0.5819 D(G(z)): 0.0212 / 0.0617\n",
      "[0/10][85/391] DisLoss: 0.6119 GenLoss: 5.6115 D(x): 0.8826 D(G(z)): 0.3521 / 0.0084\n",
      "[0/10][86/391] DisLoss: 0.4261 GenLoss: 3.6139 D(x): 0.7787 D(G(z)): 0.0898 / 0.0432\n",
      "[0/10][87/391] DisLoss: 0.4560 GenLoss: 3.1153 D(x): 0.7967 D(G(z)): 0.1634 / 0.0622\n",
      "[0/10][88/391] DisLoss: 0.7155 GenLoss: 8.2008 D(x): 0.9533 D(G(z)): 0.4273 / 0.0007\n",
      "[0/10][89/391] DisLoss: 1.3019 GenLoss: 2.1946 D(x): 0.3576 D(G(z)): 0.0083 / 0.1872\n",
      "[0/10][90/391] DisLoss: 0.6204 GenLoss: 6.5787 D(x): 0.9602 D(G(z)): 0.3731 / 0.0033\n",
      "[0/10][91/391] DisLoss: 0.5126 GenLoss: 3.3118 D(x): 0.6745 D(G(z)): 0.0258 / 0.0652\n",
      "[0/10][92/391] DisLoss: 0.5554 GenLoss: 5.0546 D(x): 0.9271 D(G(z)): 0.3258 / 0.0098\n",
      "[0/10][93/391] DisLoss: 0.3335 GenLoss: 2.8410 D(x): 0.7831 D(G(z)): 0.0371 / 0.0905\n",
      "[0/10][94/391] DisLoss: 0.8426 GenLoss: 8.3083 D(x): 0.9233 D(G(z)): 0.4643 / 0.0011\n",
      "[0/10][95/391] DisLoss: 1.3807 GenLoss: 1.1416 D(x): 0.3663 D(G(z)): 0.0038 / 0.4008\n",
      "[0/10][96/391] DisLoss: 1.3390 GenLoss: 8.8802 D(x): 0.9445 D(G(z)): 0.6343 / 0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][97/391] DisLoss: 0.9351 GenLoss: 2.8239 D(x): 0.4596 D(G(z)): 0.0021 / 0.0843\n",
      "[0/10][98/391] DisLoss: 0.4604 GenLoss: 2.2571 D(x): 0.8774 D(G(z)): 0.2262 / 0.1300\n",
      "[0/10][99/391] DisLoss: 0.5898 GenLoss: 5.0801 D(x): 0.9091 D(G(z)): 0.3403 / 0.0107\n",
      "[0/10][100/391] DisLoss: 0.8086 GenLoss: 1.8898 D(x): 0.5512 D(G(z)): 0.0422 / 0.2140\n",
      "[0/10][101/391] DisLoss: 0.9898 GenLoss: 5.8564 D(x): 0.9175 D(G(z)): 0.5290 / 0.0068\n",
      "[0/10][102/391] DisLoss: 0.8972 GenLoss: 2.4159 D(x): 0.5080 D(G(z)): 0.0247 / 0.1229\n",
      "[0/10][103/391] DisLoss: 0.4617 GenLoss: 3.3032 D(x): 0.9309 D(G(z)): 0.2944 / 0.0494\n",
      "[0/10][104/391] DisLoss: 0.3042 GenLoss: 3.7848 D(x): 0.8793 D(G(z)): 0.1478 / 0.0295\n",
      "[0/10][105/391] DisLoss: 0.4379 GenLoss: 2.5136 D(x): 0.7669 D(G(z)): 0.1041 / 0.0997\n",
      "[0/10][106/391] DisLoss: 0.4032 GenLoss: 4.0190 D(x): 0.8921 D(G(z)): 0.2327 / 0.0273\n",
      "[0/10][107/391] DisLoss: 0.4118 GenLoss: 3.0438 D(x): 0.7612 D(G(z)): 0.0962 / 0.0592\n",
      "[0/10][108/391] DisLoss: 0.4475 GenLoss: 5.8833 D(x): 0.9187 D(G(z)): 0.2870 / 0.0051\n",
      "[0/10][109/391] DisLoss: 0.6787 GenLoss: 2.5246 D(x): 0.5745 D(G(z)): 0.0150 / 0.0994\n",
      "[0/10][110/391] DisLoss: 0.4455 GenLoss: 4.5737 D(x): 0.9476 D(G(z)): 0.3019 / 0.0152\n",
      "[0/10][111/391] DisLoss: 0.1397 GenLoss: 4.6958 D(x): 0.9273 D(G(z)): 0.0581 / 0.0139\n",
      "[0/10][112/391] DisLoss: 0.2360 GenLoss: 3.9267 D(x): 0.9156 D(G(z)): 0.1281 / 0.0262\n",
      "[0/10][113/391] DisLoss: 0.2417 GenLoss: 4.2414 D(x): 0.9138 D(G(z)): 0.1308 / 0.0193\n",
      "[0/10][114/391] DisLoss: 0.4983 GenLoss: 2.6222 D(x): 0.7424 D(G(z)): 0.1244 / 0.0868\n",
      "[0/10][115/391] DisLoss: 0.6838 GenLoss: 5.6137 D(x): 0.8818 D(G(z)): 0.4008 / 0.0064\n",
      "[0/10][116/391] DisLoss: 0.6288 GenLoss: 2.2803 D(x): 0.6098 D(G(z)): 0.0287 / 0.1572\n",
      "[0/10][117/391] DisLoss: 0.6873 GenLoss: 5.4499 D(x): 0.9771 D(G(z)): 0.4381 / 0.0086\n",
      "[0/10][118/391] DisLoss: 0.2895 GenLoss: 5.0061 D(x): 0.8468 D(G(z)): 0.0607 / 0.0096\n",
      "[0/10][119/391] DisLoss: 0.1540 GenLoss: 3.6863 D(x): 0.9020 D(G(z)): 0.0421 / 0.0405\n",
      "[0/10][120/391] DisLoss: 0.2983 GenLoss: 3.6664 D(x): 0.9035 D(G(z)): 0.1605 / 0.0331\n",
      "[0/10][121/391] DisLoss: 0.4743 GenLoss: 6.4664 D(x): 0.9167 D(G(z)): 0.2915 / 0.0026\n",
      "[0/10][122/391] DisLoss: 0.5973 GenLoss: 2.9945 D(x): 0.6131 D(G(z)): 0.0141 / 0.0699\n",
      "[0/10][123/391] DisLoss: 0.5415 GenLoss: 6.9590 D(x): 0.9534 D(G(z)): 0.3586 / 0.0018\n",
      "[0/10][124/391] DisLoss: 0.6052 GenLoss: 3.6508 D(x): 0.5978 D(G(z)): 0.0086 / 0.0383\n",
      "[0/10][125/391] DisLoss: 0.3294 GenLoss: 4.8625 D(x): 0.9286 D(G(z)): 0.2085 / 0.0126\n",
      "[0/10][126/391] DisLoss: 0.1887 GenLoss: 4.6548 D(x): 0.8983 D(G(z)): 0.0681 / 0.0163\n",
      "[0/10][127/391] DisLoss: 0.0920 GenLoss: 4.8693 D(x): 0.9659 D(G(z)): 0.0530 / 0.0137\n",
      "[0/10][128/391] DisLoss: 0.1321 GenLoss: 4.2413 D(x): 0.9404 D(G(z)): 0.0637 / 0.0197\n",
      "[0/10][129/391] DisLoss: 0.3553 GenLoss: 3.9779 D(x): 0.8535 D(G(z)): 0.1593 / 0.0238\n",
      "[0/10][130/391] DisLoss: 0.3508 GenLoss: 5.4586 D(x): 0.9104 D(G(z)): 0.2109 / 0.0058\n",
      "[0/10][131/391] DisLoss: 0.6609 GenLoss: 1.2596 D(x): 0.5941 D(G(z)): 0.0650 / 0.3313\n",
      "[0/10][132/391] DisLoss: 1.3890 GenLoss: 10.7127 D(x): 0.9670 D(G(z)): 0.7018 / 0.0001\n",
      "[0/10][133/391] DisLoss: 4.1938 GenLoss: 2.6646 D(x): 0.0322 D(G(z)): 0.0012 / 0.1675\n",
      "[0/10][134/391] DisLoss: 0.7751 GenLoss: 4.1861 D(x): 0.8742 D(G(z)): 0.3650 / 0.0309\n",
      "[0/10][135/391] DisLoss: 0.4651 GenLoss: 3.7726 D(x): 0.8042 D(G(z)): 0.1589 / 0.0477\n",
      "[0/10][136/391] DisLoss: 0.7892 GenLoss: 1.9191 D(x): 0.6674 D(G(z)): 0.1704 / 0.2220\n",
      "[0/10][137/391] DisLoss: 0.8773 GenLoss: 7.0356 D(x): 0.9593 D(G(z)): 0.5086 / 0.0016\n",
      "[0/10][138/391] DisLoss: 1.1395 GenLoss: 2.8654 D(x): 0.4174 D(G(z)): 0.0090 / 0.0757\n",
      "[0/10][139/391] DisLoss: 0.2761 GenLoss: 2.9198 D(x): 0.9710 D(G(z)): 0.2022 / 0.0661\n",
      "[0/10][140/391] DisLoss: 0.3364 GenLoss: 4.9664 D(x): 0.9773 D(G(z)): 0.2462 / 0.0111\n",
      "[0/10][141/391] DisLoss: 0.2117 GenLoss: 4.4970 D(x): 0.8918 D(G(z)): 0.0770 / 0.0184\n",
      "[0/10][142/391] DisLoss: 0.4357 GenLoss: 3.0472 D(x): 0.8180 D(G(z)): 0.1690 / 0.0669\n",
      "[0/10][143/391] DisLoss: 0.8590 GenLoss: 6.3947 D(x): 0.8586 D(G(z)): 0.4495 / 0.0026\n",
      "[0/10][144/391] DisLoss: 0.6531 GenLoss: 3.5541 D(x): 0.6308 D(G(z)): 0.0454 / 0.0457\n",
      "[0/10][145/391] DisLoss: 0.3828 GenLoss: 3.4518 D(x): 0.8615 D(G(z)): 0.1765 / 0.0473\n",
      "[0/10][146/391] DisLoss: 0.8868 GenLoss: 9.8771 D(x): 0.9039 D(G(z)): 0.4746 / 0.0001\n",
      "[0/10][147/391] DisLoss: 1.8110 GenLoss: 5.1571 D(x): 0.2974 D(G(z)): 0.0015 / 0.0213\n",
      "[0/10][148/391] DisLoss: 0.3652 GenLoss: 3.7069 D(x): 0.9616 D(G(z)): 0.2116 / 0.0527\n",
      "[0/10][149/391] DisLoss: 2.1678 GenLoss: 10.9442 D(x): 0.9723 D(G(z)): 0.7851 / 0.0001\n",
      "[0/10][150/391] DisLoss: 3.0101 GenLoss: 5.2969 D(x): 0.1560 D(G(z)): 0.0010 / 0.0176\n",
      "[0/10][151/391] DisLoss: 0.7195 GenLoss: 1.9272 D(x): 0.6853 D(G(z)): 0.1571 / 0.2359\n",
      "[0/10][152/391] DisLoss: 1.4405 GenLoss: 7.4452 D(x): 0.9351 D(G(z)): 0.6473 / 0.0018\n",
      "[0/10][153/391] DisLoss: 1.4045 GenLoss: 4.5901 D(x): 0.3957 D(G(z)): 0.0087 / 0.0237\n",
      "[0/10][154/391] DisLoss: 0.3581 GenLoss: 2.4874 D(x): 0.8537 D(G(z)): 0.1315 / 0.1270\n",
      "[0/10][155/391] DisLoss: 0.8510 GenLoss: 4.3111 D(x): 0.9269 D(G(z)): 0.4848 / 0.0210\n",
      "[0/10][156/391] DisLoss: 0.4368 GenLoss: 3.9743 D(x): 0.7572 D(G(z)): 0.0838 / 0.0312\n",
      "[0/10][157/391] DisLoss: 0.5099 GenLoss: 2.5949 D(x): 0.7768 D(G(z)): 0.1379 / 0.0992\n",
      "[0/10][158/391] DisLoss: 0.4583 GenLoss: 3.0793 D(x): 0.9153 D(G(z)): 0.2707 / 0.0610\n",
      "[0/10][159/391] DisLoss: 0.3910 GenLoss: 3.6520 D(x): 0.8908 D(G(z)): 0.2220 / 0.0325\n",
      "[0/10][160/391] DisLoss: 0.4996 GenLoss: 3.0445 D(x): 0.7685 D(G(z)): 0.1381 / 0.0624\n",
      "[0/10][161/391] DisLoss: 0.4532 GenLoss: 2.7537 D(x): 0.8084 D(G(z)): 0.1811 / 0.0819\n",
      "[0/10][162/391] DisLoss: 0.3529 GenLoss: 3.5893 D(x): 0.9003 D(G(z)): 0.2005 / 0.0357\n",
      "[0/10][163/391] DisLoss: 0.4050 GenLoss: 3.1947 D(x): 0.7990 D(G(z)): 0.1303 / 0.0497\n",
      "[0/10][164/391] DisLoss: 0.3430 GenLoss: 2.9128 D(x): 0.8282 D(G(z)): 0.1226 / 0.0662\n",
      "[0/10][165/391] DisLoss: 0.2874 GenLoss: 4.3535 D(x): 0.9549 D(G(z)): 0.2043 / 0.0165\n",
      "[0/10][166/391] DisLoss: 0.2147 GenLoss: 4.2933 D(x): 0.8755 D(G(z)): 0.0676 / 0.0180\n",
      "[0/10][167/391] DisLoss: 0.4020 GenLoss: 2.7184 D(x): 0.7627 D(G(z)): 0.0704 / 0.0898\n",
      "[0/10][168/391] DisLoss: 0.6676 GenLoss: 7.6923 D(x): 0.9593 D(G(z)): 0.4280 / 0.0008\n",
      "[0/10][169/391] DisLoss: 0.5660 GenLoss: 5.6679 D(x): 0.6398 D(G(z)): 0.0063 / 0.0089\n",
      "[0/10][170/391] DisLoss: 0.3786 GenLoss: 2.7255 D(x): 0.7851 D(G(z)): 0.0480 / 0.1088\n",
      "[0/10][171/391] DisLoss: 0.9551 GenLoss: 7.3454 D(x): 0.9557 D(G(z)): 0.5327 / 0.0012\n",
      "[0/10][172/391] DisLoss: 1.2214 GenLoss: 3.8007 D(x): 0.3858 D(G(z)): 0.0087 / 0.0438\n",
      "[0/10][173/391] DisLoss: 0.4192 GenLoss: 3.4710 D(x): 0.8766 D(G(z)): 0.1992 / 0.0518\n",
      "[0/10][174/391] DisLoss: 0.6986 GenLoss: 7.6115 D(x): 0.9601 D(G(z)): 0.4344 / 0.0009\n",
      "[0/10][175/391] DisLoss: 0.7514 GenLoss: 4.0959 D(x): 0.5462 D(G(z)): 0.0110 / 0.0325\n",
      "[0/10][176/391] DisLoss: 0.6226 GenLoss: 5.0124 D(x): 0.8577 D(G(z)): 0.3153 / 0.0153\n",
      "[0/10][177/391] DisLoss: 0.6009 GenLoss: 3.6747 D(x): 0.6983 D(G(z)): 0.1316 / 0.0367\n",
      "[0/10][178/391] DisLoss: 0.4929 GenLoss: 4.4307 D(x): 0.8401 D(G(z)): 0.2332 / 0.0184\n",
      "[0/10][179/391] DisLoss: 0.3036 GenLoss: 4.2091 D(x): 0.8496 D(G(z)): 0.0956 / 0.0180\n",
      "[0/10][180/391] DisLoss: 0.1952 GenLoss: 3.8924 D(x): 0.9031 D(G(z)): 0.0788 / 0.0258\n",
      "[0/10][181/391] DisLoss: 0.1479 GenLoss: 4.1389 D(x): 0.9529 D(G(z)): 0.0895 / 0.0213\n",
      "[0/10][182/391] DisLoss: 0.1962 GenLoss: 4.1533 D(x): 0.9389 D(G(z)): 0.1178 / 0.0193\n",
      "[0/10][183/391] DisLoss: 0.2459 GenLoss: 4.1691 D(x): 0.8989 D(G(z)): 0.1183 / 0.0211\n",
      "[0/10][184/391] DisLoss: 0.3009 GenLoss: 3.4508 D(x): 0.8399 D(G(z)): 0.0886 / 0.0410\n",
      "[0/10][185/391] DisLoss: 0.3350 GenLoss: 4.0596 D(x): 0.8930 D(G(z)): 0.1828 / 0.0239\n",
      "[0/10][186/391] DisLoss: 0.3294 GenLoss: 4.0194 D(x): 0.8575 D(G(z)): 0.1322 / 0.0238\n",
      "[0/10][187/391] DisLoss: 0.3153 GenLoss: 4.3324 D(x): 0.8717 D(G(z)): 0.1487 / 0.0172\n",
      "[0/10][188/391] DisLoss: 0.2466 GenLoss: 4.4795 D(x): 0.8961 D(G(z)): 0.1139 / 0.0163\n",
      "[0/10][189/391] DisLoss: 0.3783 GenLoss: 3.6778 D(x): 0.8085 D(G(z)): 0.1241 / 0.0356\n",
      "[0/10][190/391] DisLoss: 0.7243 GenLoss: 5.7312 D(x): 0.7833 D(G(z)): 0.3329 / 0.0061\n",
      "[0/10][191/391] DisLoss: 0.5262 GenLoss: 3.0997 D(x): 0.6875 D(G(z)): 0.0693 / 0.0648\n",
      "[0/10][192/391] DisLoss: 0.7356 GenLoss: 7.0228 D(x): 0.8697 D(G(z)): 0.4062 / 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][193/391] DisLoss: 0.4766 GenLoss: 4.3651 D(x): 0.6738 D(G(z)): 0.0167 / 0.0227\n",
      "[0/10][194/391] DisLoss: 0.3919 GenLoss: 3.0462 D(x): 0.8413 D(G(z)): 0.1652 / 0.0724\n",
      "[0/10][195/391] DisLoss: 0.7133 GenLoss: 6.0731 D(x): 0.8607 D(G(z)): 0.3914 / 0.0040\n",
      "[0/10][196/391] DisLoss: 0.5310 GenLoss: 3.6008 D(x): 0.6467 D(G(z)): 0.0265 / 0.0414\n",
      "[0/10][197/391] DisLoss: 0.5060 GenLoss: 4.5267 D(x): 0.9129 D(G(z)): 0.2916 / 0.0166\n",
      "[0/10][198/391] DisLoss: 0.6351 GenLoss: 2.5158 D(x): 0.6687 D(G(z)): 0.1261 / 0.1068\n",
      "[0/10][199/391] DisLoss: 1.2425 GenLoss: 9.9853 D(x): 0.9200 D(G(z)): 0.6326 / 0.0002\n",
      "[0/10][200/391] DisLoss: 2.5073 GenLoss: 3.5732 D(x): 0.1624 D(G(z)): 0.0017 / 0.0623\n",
      "[0/10][201/391] DisLoss: 0.7301 GenLoss: 4.5715 D(x): 0.9208 D(G(z)): 0.4034 / 0.0191\n",
      "[0/10][202/391] DisLoss: 0.6741 GenLoss: 4.5019 D(x): 0.7508 D(G(z)): 0.2327 / 0.0244\n",
      "[0/10][203/391] DisLoss: 0.6509 GenLoss: 4.3210 D(x): 0.7947 D(G(z)): 0.2837 / 0.0224\n",
      "[0/10][204/391] DisLoss: 0.9085 GenLoss: 2.7683 D(x): 0.6045 D(G(z)): 0.2244 / 0.0931\n",
      "[0/10][205/391] DisLoss: 1.3921 GenLoss: 5.6031 D(x): 0.7335 D(G(z)): 0.5635 / 0.0062\n",
      "[0/10][206/391] DisLoss: 0.9761 GenLoss: 2.3405 D(x): 0.4997 D(G(z)): 0.0631 / 0.1387\n",
      "[0/10][207/391] DisLoss: 1.4552 GenLoss: 7.6466 D(x): 0.9302 D(G(z)): 0.6826 / 0.0009\n",
      "[0/10][208/391] DisLoss: 1.0007 GenLoss: 5.3532 D(x): 0.4639 D(G(z)): 0.0071 / 0.0086\n",
      "[0/10][209/391] DisLoss: 0.4221 GenLoss: 2.4132 D(x): 0.7446 D(G(z)): 0.0480 / 0.1336\n",
      "[0/10][210/391] DisLoss: 0.5632 GenLoss: 4.3280 D(x): 0.9507 D(G(z)): 0.3621 / 0.0195\n",
      "[0/10][211/391] DisLoss: 0.2679 GenLoss: 4.4394 D(x): 0.8656 D(G(z)): 0.0954 / 0.0183\n",
      "[0/10][212/391] DisLoss: 0.2567 GenLoss: 3.4381 D(x): 0.8630 D(G(z)): 0.0887 / 0.0444\n",
      "[0/10][213/391] DisLoss: 0.2073 GenLoss: 3.4601 D(x): 0.8993 D(G(z)): 0.0858 / 0.0451\n",
      "[0/10][214/391] DisLoss: 0.4068 GenLoss: 4.3496 D(x): 0.9288 D(G(z)): 0.2597 / 0.0189\n",
      "[0/10][215/391] DisLoss: 0.4067 GenLoss: 2.8601 D(x): 0.7394 D(G(z)): 0.0620 / 0.0788\n",
      "[0/10][216/391] DisLoss: 0.4631 GenLoss: 4.5418 D(x): 0.9136 D(G(z)): 0.2880 / 0.0164\n",
      "[0/10][217/391] DisLoss: 0.2064 GenLoss: 4.6632 D(x): 0.8684 D(G(z)): 0.0527 / 0.0171\n",
      "[0/10][218/391] DisLoss: 0.3198 GenLoss: 2.9766 D(x): 0.8222 D(G(z)): 0.0920 / 0.0712\n",
      "[0/10][219/391] DisLoss: 0.6543 GenLoss: 7.0997 D(x): 0.8967 D(G(z)): 0.3796 / 0.0017\n",
      "[0/10][220/391] DisLoss: 1.6152 GenLoss: 1.2431 D(x): 0.2981 D(G(z)): 0.0145 / 0.3733\n",
      "[0/10][221/391] DisLoss: 1.3662 GenLoss: 8.2729 D(x): 0.9775 D(G(z)): 0.6612 / 0.0007\n",
      "[0/10][222/391] DisLoss: 0.6320 GenLoss: 6.3996 D(x): 0.6248 D(G(z)): 0.0039 / 0.0031\n",
      "[0/10][223/391] DisLoss: 0.2177 GenLoss: 3.6214 D(x): 0.8479 D(G(z)): 0.0253 / 0.0497\n",
      "[0/10][224/391] DisLoss: 0.3355 GenLoss: 3.3909 D(x): 0.9297 D(G(z)): 0.1967 / 0.0499\n",
      "[0/10][225/391] DisLoss: 0.3246 GenLoss: 4.2346 D(x): 0.9377 D(G(z)): 0.2117 / 0.0196\n",
      "[0/10][226/391] DisLoss: 0.1867 GenLoss: 4.2942 D(x): 0.8738 D(G(z)): 0.0387 / 0.0210\n",
      "[0/10][227/391] DisLoss: 0.3368 GenLoss: 3.1503 D(x): 0.8578 D(G(z)): 0.1447 / 0.0573\n",
      "[0/10][228/391] DisLoss: 0.4889 GenLoss: 5.2525 D(x): 0.9193 D(G(z)): 0.2985 / 0.0072\n",
      "[0/10][229/391] DisLoss: 0.5727 GenLoss: 2.6915 D(x): 0.6410 D(G(z)): 0.0447 / 0.0942\n",
      "[0/10][230/391] DisLoss: 0.8359 GenLoss: 7.2846 D(x): 0.8840 D(G(z)): 0.4639 / 0.0015\n",
      "[0/10][231/391] DisLoss: 2.2033 GenLoss: 1.6456 D(x): 0.1906 D(G(z)): 0.0061 / 0.2724\n",
      "[0/10][232/391] DisLoss: 1.4136 GenLoss: 7.7119 D(x): 0.9670 D(G(z)): 0.6681 / 0.0010\n",
      "[0/10][233/391] DisLoss: 0.8131 GenLoss: 4.4701 D(x): 0.5512 D(G(z)): 0.0149 / 0.0256\n",
      "[0/10][234/391] DisLoss: 0.4204 GenLoss: 2.3216 D(x): 0.7893 D(G(z)): 0.0689 / 0.1561\n",
      "[0/10][235/391] DisLoss: 0.7259 GenLoss: 3.7433 D(x): 0.9636 D(G(z)): 0.4440 / 0.0373\n",
      "[0/10][236/391] DisLoss: 0.4211 GenLoss: 3.8075 D(x): 0.8157 D(G(z)): 0.1447 / 0.0311\n",
      "[0/10][237/391] DisLoss: 0.5249 GenLoss: 2.9120 D(x): 0.7717 D(G(z)): 0.1643 / 0.0864\n",
      "[0/10][238/391] DisLoss: 0.6032 GenLoss: 3.1186 D(x): 0.7920 D(G(z)): 0.2535 / 0.0572\n",
      "[0/10][239/391] DisLoss: 0.6850 GenLoss: 3.5707 D(x): 0.7374 D(G(z)): 0.2784 / 0.0365\n",
      "[0/10][240/391] DisLoss: 0.4486 GenLoss: 3.2746 D(x): 0.7836 D(G(z)): 0.1443 / 0.0504\n",
      "[0/10][241/391] DisLoss: 0.3608 GenLoss: 3.5313 D(x): 0.8461 D(G(z)): 0.1515 / 0.0397\n",
      "[0/10][242/391] DisLoss: 0.3578 GenLoss: 3.8662 D(x): 0.8514 D(G(z)): 0.1402 / 0.0322\n",
      "[0/10][243/391] DisLoss: 0.4827 GenLoss: 3.9785 D(x): 0.8188 D(G(z)): 0.1859 / 0.0307\n",
      "[0/10][244/391] DisLoss: 0.6088 GenLoss: 2.6094 D(x): 0.7003 D(G(z)): 0.1310 / 0.1204\n",
      "[0/10][245/391] DisLoss: 0.6981 GenLoss: 6.7385 D(x): 0.8870 D(G(z)): 0.3778 / 0.0035\n",
      "[0/10][246/391] DisLoss: 0.6027 GenLoss: 4.3536 D(x): 0.6501 D(G(z)): 0.0188 / 0.0385\n",
      "[0/10][247/391] DisLoss: 0.5050 GenLoss: 2.2779 D(x): 0.8059 D(G(z)): 0.1615 / 0.1469\n",
      "[0/10][248/391] DisLoss: 1.0320 GenLoss: 6.2671 D(x): 0.9025 D(G(z)): 0.5274 / 0.0034\n",
      "[0/10][249/391] DisLoss: 1.1345 GenLoss: 3.0610 D(x): 0.4232 D(G(z)): 0.0136 / 0.1093\n",
      "[0/10][250/391] DisLoss: 0.5130 GenLoss: 4.0129 D(x): 0.9484 D(G(z)): 0.2891 / 0.0470\n",
      "[0/10][251/391] DisLoss: 0.5266 GenLoss: 6.4512 D(x): 0.9463 D(G(z)): 0.3163 / 0.0031\n",
      "[0/10][252/391] DisLoss: 0.9119 GenLoss: 3.0821 D(x): 0.4889 D(G(z)): 0.0158 / 0.0839\n",
      "[0/10][253/391] DisLoss: 1.1015 GenLoss: 5.4381 D(x): 0.9337 D(G(z)): 0.5582 / 0.0101\n",
      "[0/10][254/391] DisLoss: 0.8058 GenLoss: 3.3476 D(x): 0.5767 D(G(z)): 0.0948 / 0.0636\n",
      "[0/10][255/391] DisLoss: 0.4649 GenLoss: 4.4245 D(x): 0.9526 D(G(z)): 0.3008 / 0.0239\n",
      "[0/10][256/391] DisLoss: 0.3895 GenLoss: 3.7329 D(x): 0.7658 D(G(z)): 0.0796 / 0.0389\n",
      "[0/10][257/391] DisLoss: 0.3220 GenLoss: 3.9083 D(x): 0.9116 D(G(z)): 0.1810 / 0.0320\n",
      "[0/10][258/391] DisLoss: 0.2192 GenLoss: 4.0477 D(x): 0.8944 D(G(z)): 0.0877 / 0.0266\n",
      "[0/10][259/391] DisLoss: 0.2653 GenLoss: 4.1258 D(x): 0.9226 D(G(z)): 0.1559 / 0.0228\n",
      "[0/10][260/391] DisLoss: 0.1793 GenLoss: 4.7369 D(x): 0.9499 D(G(z)): 0.1138 / 0.0124\n",
      "[0/10][261/391] DisLoss: 0.4526 GenLoss: 3.1178 D(x): 0.7526 D(G(z)): 0.1076 / 0.0635\n",
      "[0/10][262/391] DisLoss: 0.7220 GenLoss: 7.3267 D(x): 0.9493 D(G(z)): 0.4490 / 0.0013\n",
      "[0/10][263/391] DisLoss: 0.8372 GenLoss: 3.9195 D(x): 0.5296 D(G(z)): 0.0170 / 0.0327\n",
      "[0/10][264/391] DisLoss: 0.4875 GenLoss: 4.6453 D(x): 0.9291 D(G(z)): 0.3028 / 0.0134\n",
      "[0/10][265/391] DisLoss: 0.4388 GenLoss: 4.2788 D(x): 0.7900 D(G(z)): 0.1322 / 0.0206\n",
      "[0/10][266/391] DisLoss: 0.3029 GenLoss: 5.2543 D(x): 0.9307 D(G(z)): 0.1900 / 0.0071\n",
      "[0/10][267/391] DisLoss: 0.5134 GenLoss: 3.1607 D(x): 0.6749 D(G(z)): 0.0413 / 0.0590\n",
      "[0/10][268/391] DisLoss: 0.5757 GenLoss: 5.7123 D(x): 0.9659 D(G(z)): 0.3849 / 0.0052\n",
      "[0/10][269/391] DisLoss: 0.2962 GenLoss: 4.7979 D(x): 0.7886 D(G(z)): 0.0312 / 0.0109\n",
      "[0/10][270/391] DisLoss: 0.1484 GenLoss: 3.8910 D(x): 0.9293 D(G(z)): 0.0673 / 0.0288\n",
      "[0/10][271/391] DisLoss: 0.1882 GenLoss: 3.7009 D(x): 0.9262 D(G(z)): 0.0978 / 0.0371\n",
      "[0/10][272/391] DisLoss: 0.3636 GenLoss: 4.9062 D(x): 0.9704 D(G(z)): 0.2690 / 0.0091\n",
      "[0/10][273/391] DisLoss: 0.3489 GenLoss: 3.7343 D(x): 0.7551 D(G(z)): 0.0349 / 0.0283\n",
      "[0/10][274/391] DisLoss: 0.2785 GenLoss: 2.7635 D(x): 0.8671 D(G(z)): 0.1112 / 0.0765\n",
      "[0/10][275/391] DisLoss: 0.5853 GenLoss: 6.6784 D(x): 0.9530 D(G(z)): 0.3987 / 0.0020\n",
      "[0/10][276/391] DisLoss: 0.4750 GenLoss: 5.6809 D(x): 0.6659 D(G(z)): 0.0050 / 0.0059\n",
      "[0/10][277/391] DisLoss: 0.4270 GenLoss: 1.5077 D(x): 0.7291 D(G(z)): 0.0632 / 0.2674\n",
      "[0/10][278/391] DisLoss: 1.3293 GenLoss: 9.8709 D(x): 0.9877 D(G(z)): 0.6913 / 0.0001\n",
      "[0/10][279/391] DisLoss: 1.4301 GenLoss: 6.3038 D(x): 0.3314 D(G(z)): 0.0014 / 0.0049\n",
      "[0/10][280/391] DisLoss: 0.1917 GenLoss: 3.4844 D(x): 0.8602 D(G(z)): 0.0148 / 0.0605\n",
      "[0/10][281/391] DisLoss: 0.6713 GenLoss: 5.5574 D(x): 0.9726 D(G(z)): 0.3925 / 0.0057\n",
      "[0/10][282/391] DisLoss: 0.2046 GenLoss: 5.7484 D(x): 0.9015 D(G(z)): 0.0772 / 0.0050\n",
      "[0/10][283/391] DisLoss: 0.2573 GenLoss: 4.1035 D(x): 0.8286 D(G(z)): 0.0444 / 0.0290\n",
      "[0/10][284/391] DisLoss: 0.5724 GenLoss: 4.0831 D(x): 0.8020 D(G(z)): 0.2559 / 0.0250\n",
      "[0/10][285/391] DisLoss: 0.6348 GenLoss: 4.4363 D(x): 0.7500 D(G(z)): 0.2416 / 0.0171\n",
      "[0/10][286/391] DisLoss: 0.9029 GenLoss: 1.3395 D(x): 0.5011 D(G(z)): 0.0544 / 0.3675\n",
      "[0/10][287/391] DisLoss: 1.3812 GenLoss: 9.3495 D(x): 0.9633 D(G(z)): 0.6695 / 0.0002\n",
      "[0/10][288/391] DisLoss: 2.1746 GenLoss: 6.0634 D(x): 0.2169 D(G(z)): 0.0007 / 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][289/391] DisLoss: 0.1379 GenLoss: 3.5316 D(x): 0.8993 D(G(z)): 0.0169 / 0.0497\n",
      "[0/10][290/391] DisLoss: 0.4109 GenLoss: 4.3684 D(x): 0.9449 D(G(z)): 0.2579 / 0.0210\n",
      "[0/10][291/391] DisLoss: 0.4215 GenLoss: 2.9885 D(x): 0.7657 D(G(z)): 0.0929 / 0.0812\n",
      "[0/10][292/391] DisLoss: 0.4127 GenLoss: 4.6826 D(x): 0.9737 D(G(z)): 0.2928 / 0.0150\n",
      "[0/10][293/391] DisLoss: 0.6122 GenLoss: 3.0580 D(x): 0.6947 D(G(z)): 0.1291 / 0.0732\n",
      "[0/10][294/391] DisLoss: 0.3918 GenLoss: 4.2461 D(x): 0.9098 D(G(z)): 0.2290 / 0.0221\n",
      "[0/10][295/391] DisLoss: 0.2620 GenLoss: 4.8160 D(x): 0.9122 D(G(z)): 0.1250 / 0.0124\n",
      "[0/10][296/391] DisLoss: 0.4896 GenLoss: 2.9354 D(x): 0.7448 D(G(z)): 0.0991 / 0.0702\n",
      "[0/10][297/391] DisLoss: 0.3991 GenLoss: 4.9963 D(x): 0.9371 D(G(z)): 0.2566 / 0.0098\n",
      "[0/10][298/391] DisLoss: 0.3160 GenLoss: 4.7403 D(x): 0.8475 D(G(z)): 0.1127 / 0.0127\n",
      "[0/10][299/391] DisLoss: 0.4511 GenLoss: 3.3419 D(x): 0.7789 D(G(z)): 0.1316 / 0.0506\n",
      "[0/10][300/391] DisLoss: 0.5947 GenLoss: 5.6776 D(x): 0.8676 D(G(z)): 0.3202 / 0.0052\n",
      "[0/10][301/391] DisLoss: 0.6486 GenLoss: 2.7649 D(x): 0.6083 D(G(z)): 0.0431 / 0.1016\n",
      "[0/10][302/391] DisLoss: 1.0559 GenLoss: 8.4780 D(x): 0.9471 D(G(z)): 0.5597 / 0.0004\n",
      "[0/10][303/391] DisLoss: 1.0691 GenLoss: 4.5699 D(x): 0.4413 D(G(z)): 0.0034 / 0.0211\n",
      "[0/10][304/391] DisLoss: 0.2384 GenLoss: 2.9391 D(x): 0.8960 D(G(z)): 0.1032 / 0.1011\n",
      "[0/10][305/391] DisLoss: 0.6228 GenLoss: 7.3214 D(x): 0.9616 D(G(z)): 0.3789 / 0.0012\n",
      "[0/10][306/391] DisLoss: 0.4596 GenLoss: 4.3630 D(x): 0.7036 D(G(z)): 0.0325 / 0.0267\n",
      "[0/10][307/391] DisLoss: 0.3391 GenLoss: 3.2020 D(x): 0.8340 D(G(z)): 0.1142 / 0.0596\n",
      "[0/10][308/391] DisLoss: 1.0271 GenLoss: 9.3155 D(x): 0.9128 D(G(z)): 0.5405 / 0.0002\n",
      "[0/10][309/391] DisLoss: 3.1944 GenLoss: 2.4458 D(x): 0.0875 D(G(z)): 0.0024 / 0.1161\n",
      "[0/10][310/391] DisLoss: 0.6971 GenLoss: 4.4380 D(x): 0.8911 D(G(z)): 0.3980 / 0.0255\n",
      "[0/10][311/391] DisLoss: 0.3102 GenLoss: 5.1361 D(x): 0.8651 D(G(z)): 0.1169 / 0.0119\n",
      "[0/10][312/391] DisLoss: 0.4033 GenLoss: 3.2437 D(x): 0.7833 D(G(z)): 0.0908 / 0.0656\n",
      "[0/10][313/391] DisLoss: 0.5043 GenLoss: 5.0642 D(x): 0.9021 D(G(z)): 0.2888 / 0.0103\n",
      "[0/10][314/391] DisLoss: 0.3158 GenLoss: 4.4604 D(x): 0.8163 D(G(z)): 0.0734 / 0.0225\n",
      "[0/10][315/391] DisLoss: 0.2780 GenLoss: 4.3250 D(x): 0.8881 D(G(z)): 0.1290 / 0.0241\n",
      "[0/10][316/391] DisLoss: 0.3800 GenLoss: 5.0002 D(x): 0.8881 D(G(z)): 0.1894 / 0.0137\n",
      "[0/10][317/391] DisLoss: 0.3830 GenLoss: 4.0598 D(x): 0.8001 D(G(z)): 0.0945 / 0.0281\n",
      "[0/10][318/391] DisLoss: 0.4503 GenLoss: 5.8544 D(x): 0.8766 D(G(z)): 0.2329 / 0.0062\n",
      "[0/10][319/391] DisLoss: 0.4616 GenLoss: 4.2442 D(x): 0.7429 D(G(z)): 0.0302 / 0.0304\n",
      "[0/10][320/391] DisLoss: 0.2858 GenLoss: 5.1820 D(x): 0.9689 D(G(z)): 0.1977 / 0.0097\n",
      "[0/10][321/391] DisLoss: 0.3687 GenLoss: 4.7375 D(x): 0.8557 D(G(z)): 0.1310 / 0.0145\n",
      "[0/10][322/391] DisLoss: 0.2436 GenLoss: 5.3286 D(x): 0.9313 D(G(z)): 0.1414 / 0.0088\n",
      "[0/10][323/391] DisLoss: 0.2089 GenLoss: 4.9105 D(x): 0.8879 D(G(z)): 0.0577 / 0.0123\n",
      "[0/10][324/391] DisLoss: 0.3262 GenLoss: 3.8441 D(x): 0.8441 D(G(z)): 0.1108 / 0.0334\n",
      "[0/10][325/391] DisLoss: 0.3443 GenLoss: 5.0171 D(x): 0.9255 D(G(z)): 0.1887 / 0.0095\n",
      "[0/10][326/391] DisLoss: 0.1511 GenLoss: 5.1522 D(x): 0.9185 D(G(z)): 0.0520 / 0.0082\n",
      "[0/10][327/391] DisLoss: 0.0870 GenLoss: 4.7711 D(x): 0.9607 D(G(z)): 0.0418 / 0.0129\n",
      "[0/10][328/391] DisLoss: 0.2466 GenLoss: 3.5139 D(x): 0.8575 D(G(z)): 0.0578 / 0.0458\n",
      "[0/10][329/391] DisLoss: 0.5501 GenLoss: 7.4512 D(x): 0.9690 D(G(z)): 0.3689 / 0.0013\n",
      "[0/10][330/391] DisLoss: 0.2753 GenLoss: 6.9773 D(x): 0.8018 D(G(z)): 0.0123 / 0.0021\n",
      "[0/10][331/391] DisLoss: 0.1560 GenLoss: 4.8068 D(x): 0.9093 D(G(z)): 0.0441 / 0.0228\n",
      "[0/10][332/391] DisLoss: 0.6573 GenLoss: 6.7426 D(x): 0.9146 D(G(z)): 0.3683 / 0.0028\n",
      "[0/10][333/391] DisLoss: 0.3182 GenLoss: 5.9875 D(x): 0.8191 D(G(z)): 0.0707 / 0.0054\n",
      "[0/10][334/391] DisLoss: 0.4920 GenLoss: 4.2832 D(x): 0.7465 D(G(z)): 0.0876 / 0.0247\n",
      "[0/10][335/391] DisLoss: 0.8280 GenLoss: 11.4998 D(x): 0.8504 D(G(z)): 0.4017 / 0.0000\n",
      "[0/10][336/391] DisLoss: 0.9156 GenLoss: 7.9851 D(x): 0.5783 D(G(z)): 0.0006 / 0.0033\n",
      "[0/10][337/391] DisLoss: 0.1605 GenLoss: 5.6503 D(x): 0.9296 D(G(z)): 0.0591 / 0.0175\n",
      "[0/10][338/391] DisLoss: 0.6362 GenLoss: 9.4452 D(x): 0.9874 D(G(z)): 0.3412 / 0.0005\n",
      "[0/10][339/391] DisLoss: 0.4288 GenLoss: 6.7420 D(x): 0.7910 D(G(z)): 0.0296 / 0.0072\n",
      "[0/10][340/391] DisLoss: 0.3668 GenLoss: 7.3853 D(x): 0.9385 D(G(z)): 0.1860 / 0.0022\n",
      "[0/10][341/391] DisLoss: 0.3715 GenLoss: 4.3983 D(x): 0.7892 D(G(z)): 0.0494 / 0.0213\n",
      "[0/10][342/391] DisLoss: 0.3272 GenLoss: 5.6696 D(x): 0.9226 D(G(z)): 0.1768 / 0.0083\n",
      "[0/10][343/391] DisLoss: 0.1757 GenLoss: 5.7572 D(x): 0.9178 D(G(z)): 0.0660 / 0.0066\n",
      "[0/10][344/391] DisLoss: 0.1431 GenLoss: 5.8703 D(x): 0.9475 D(G(z)): 0.0788 / 0.0055\n",
      "[0/10][345/391] DisLoss: 0.2968 GenLoss: 3.9818 D(x): 0.8241 D(G(z)): 0.0523 / 0.0352\n",
      "[0/10][346/391] DisLoss: 0.2752 GenLoss: 7.1068 D(x): 0.9762 D(G(z)): 0.2078 / 0.0012\n",
      "[0/10][347/391] DisLoss: 0.1348 GenLoss: 6.2849 D(x): 0.8993 D(G(z)): 0.0147 / 0.0029\n",
      "[0/10][348/391] DisLoss: 0.1101 GenLoss: 4.5521 D(x): 0.9297 D(G(z)): 0.0250 / 0.0169\n",
      "[0/10][349/391] DisLoss: 0.4427 GenLoss: 8.2855 D(x): 0.9237 D(G(z)): 0.2695 / 0.0009\n",
      "[0/10][350/391] DisLoss: 0.7605 GenLoss: 3.9773 D(x): 0.6286 D(G(z)): 0.0164 / 0.0424\n",
      "[0/10][351/391] DisLoss: 0.4937 GenLoss: 7.3376 D(x): 0.9422 D(G(z)): 0.3016 / 0.0009\n",
      "[0/10][352/391] DisLoss: 0.3445 GenLoss: 4.7684 D(x): 0.7729 D(G(z)): 0.0140 / 0.0183\n",
      "[0/10][353/391] DisLoss: 0.2358 GenLoss: 5.4664 D(x): 0.9510 D(G(z)): 0.1457 / 0.0098\n",
      "[0/10][354/391] DisLoss: 0.3954 GenLoss: 5.4840 D(x): 0.8432 D(G(z)): 0.1300 / 0.0087\n",
      "[0/10][355/391] DisLoss: 0.2538 GenLoss: 5.5776 D(x): 0.9025 D(G(z)): 0.1167 / 0.0070\n",
      "[0/10][356/391] DisLoss: 0.3256 GenLoss: 7.0245 D(x): 0.9210 D(G(z)): 0.1858 / 0.0016\n",
      "[0/10][357/391] DisLoss: 0.8170 GenLoss: 1.5014 D(x): 0.5644 D(G(z)): 0.0259 / 0.3169\n",
      "[0/10][358/391] DisLoss: 1.4660 GenLoss: 12.2386 D(x): 0.9777 D(G(z)): 0.6717 / 0.0001\n",
      "[0/10][359/391] DisLoss: 1.5256 GenLoss: 8.7928 D(x): 0.3516 D(G(z)): 0.0006 / 0.0051\n",
      "[0/10][360/391] DisLoss: 0.2697 GenLoss: 3.9228 D(x): 0.8402 D(G(z)): 0.0328 / 0.0664\n",
      "[0/10][361/391] DisLoss: 0.7345 GenLoss: 6.2322 D(x): 0.9834 D(G(z)): 0.4080 / 0.0081\n",
      "[0/10][362/391] DisLoss: 0.5467 GenLoss: 5.2742 D(x): 0.7737 D(G(z)): 0.1354 / 0.0106\n",
      "[0/10][363/391] DisLoss: 0.3786 GenLoss: 4.1837 D(x): 0.8503 D(G(z)): 0.1473 / 0.0454\n",
      "[0/10][364/391] DisLoss: 0.6437 GenLoss: 6.8430 D(x): 0.8216 D(G(z)): 0.2806 / 0.0021\n",
      "[0/10][365/391] DisLoss: 0.4216 GenLoss: 3.9986 D(x): 0.7498 D(G(z)): 0.0546 / 0.0422\n",
      "[0/10][366/391] DisLoss: 0.5234 GenLoss: 6.4573 D(x): 0.8748 D(G(z)): 0.2711 / 0.0047\n",
      "[0/10][367/391] DisLoss: 0.9906 GenLoss: 1.3246 D(x): 0.5450 D(G(z)): 0.0367 / 0.3520\n",
      "[0/10][368/391] DisLoss: 1.8237 GenLoss: 11.2371 D(x): 0.9830 D(G(z)): 0.7736 / 0.0000\n",
      "[0/10][369/391] DisLoss: 2.4603 GenLoss: 5.0275 D(x): 0.1956 D(G(z)): 0.0007 / 0.0160\n",
      "[0/10][370/391] DisLoss: 0.5421 GenLoss: 2.8369 D(x): 0.8581 D(G(z)): 0.2430 / 0.1227\n",
      "[0/10][371/391] DisLoss: 1.0359 GenLoss: 8.0349 D(x): 0.9720 D(G(z)): 0.5402 / 0.0010\n",
      "[0/10][372/391] DisLoss: 1.4644 GenLoss: 2.9808 D(x): 0.3842 D(G(z)): 0.0057 / 0.1100\n",
      "[0/10][373/391] DisLoss: 0.6618 GenLoss: 4.3997 D(x): 0.9800 D(G(z)): 0.3999 / 0.0188\n",
      "[0/10][374/391] DisLoss: 0.4500 GenLoss: 6.4929 D(x): 0.9470 D(G(z)): 0.2665 / 0.0029\n",
      "[0/10][375/391] DisLoss: 0.8084 GenLoss: 3.3425 D(x): 0.5574 D(G(z)): 0.0178 / 0.0663\n",
      "[0/10][376/391] DisLoss: 0.9891 GenLoss: 5.5637 D(x): 0.8992 D(G(z)): 0.4844 / 0.0146\n",
      "[0/10][377/391] DisLoss: 0.7309 GenLoss: 3.0037 D(x): 0.6547 D(G(z)): 0.1122 / 0.1026\n",
      "[0/10][378/391] DisLoss: 1.8600 GenLoss: 7.4857 D(x): 0.7583 D(G(z)): 0.6590 / 0.0020\n",
      "[0/10][379/391] DisLoss: 2.6380 GenLoss: 1.2178 D(x): 0.1552 D(G(z)): 0.0330 / 0.3724\n",
      "[0/10][380/391] DisLoss: 1.8612 GenLoss: 7.6852 D(x): 0.8695 D(G(z)): 0.7296 / 0.0013\n",
      "[0/10][381/391] DisLoss: 1.6505 GenLoss: 4.4982 D(x): 0.3109 D(G(z)): 0.0095 / 0.0334\n",
      "[0/10][382/391] DisLoss: 0.4437 GenLoss: 2.9431 D(x): 0.8874 D(G(z)): 0.2109 / 0.0995\n",
      "[0/10][383/391] DisLoss: 0.6637 GenLoss: 5.1151 D(x): 0.9537 D(G(z)): 0.4048 / 0.0119\n",
      "[0/10][384/391] DisLoss: 0.5745 GenLoss: 4.0109 D(x): 0.7313 D(G(z)): 0.1240 / 0.0415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][385/391] DisLoss: 0.8528 GenLoss: 2.4299 D(x): 0.6365 D(G(z)): 0.2142 / 0.1521\n",
      "[0/10][386/391] DisLoss: 0.8080 GenLoss: 3.9618 D(x): 0.8556 D(G(z)): 0.4246 / 0.0318\n",
      "[0/10][387/391] DisLoss: 0.4740 GenLoss: 3.6591 D(x): 0.7629 D(G(z)): 0.1277 / 0.0384\n",
      "[0/10][388/391] DisLoss: 0.3729 GenLoss: 3.0106 D(x): 0.8070 D(G(z)): 0.1154 / 0.0684\n",
      "[0/10][389/391] DisLoss: 0.4875 GenLoss: 4.2411 D(x): 0.9117 D(G(z)): 0.3008 / 0.0238\n",
      "[0/10][390/391] DisLoss: 0.3473 GenLoss: 4.4891 D(x): 0.8608 D(G(z)): 0.1304 / 0.0228\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DCganOutput/real_samples.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/88/4xtm9lhx5sv3vk7z0jytr2hh0000gn/T/ipykernel_33853/1208004993.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mvutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DCganOutput/real_samples.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mvutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DCganOutput/fake_samples_epoch_%03d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DCganOutput/real_samples.png'"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        counter += 1\n",
    "        counter_list.append(counter)\n",
    "        \n",
    "       \n",
    "        real_data = data[0].to(device)\n",
    "        size_of_batch = real_data.size(0)\n",
    "        labels_tensor = torch.full((size_of_batch,), real_value, device = device).float()\n",
    "        discriminator.zero_grad()\n",
    "        dis_output = discriminator(real_data ).float()\n",
    "        dis_real_error = criterion(dis_output, labels_tensor)\n",
    "        dis_real_error.backward()\n",
    "        dis_real_output_mean = dis_output.mean().item()\n",
    "\n",
    "        \n",
    "        labels_tensor.fill_(fake_value).float()\n",
    "        noise = torch.randn(size_of_batch, noise_dimension, 1, 1, device=device)\n",
    "        fake_data = generator(noise)\n",
    "        dis_output = discriminator(fake_data.detach()).float()\n",
    "        dis_fake_error = criterion(dis_output, labels_tensor)\n",
    "        dis_fake_error.backward()\n",
    "        dis_fake_output_mean = dis_output.mean().item()\n",
    "        disriminator_optimizer.step()\n",
    "        final_dis_error = dis_real_error + dis_fake_error\n",
    "        dis_loss_list.append(final_dis_error.item())\n",
    "        \n",
    "\n",
    "       \n",
    "        labels_tensor.fill_(real_value).float()\n",
    "        generator.zero_grad()\n",
    "        gen_output = discriminator(fake_data).float()\n",
    "        gen_error = criterion(gen_output, labels_tensor)\n",
    "        gen_loss_list.append(gen_error.item())\n",
    "        gen_error.backward()\n",
    "        gen_output_mean = gen_output.mean().item()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        \n",
    "        print('[%d/%d][%d/%d] DisLoss: %.4f GenLoss: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % \n",
    "              (epoch, num_epochs, i, len(data_loader), final_dis_error.item(), \n",
    "               gen_error.item(), dis_real_output_mean, dis_fake_output_mean, gen_output_mean ))\n",
    "        \n",
    "  \n",
    "    fake_data = generator(noise)\n",
    "    vutils.save_image(real_data,'DCganOutput/real_samples.png',normalize=True)\n",
    "    vutils.save_image(fake_data.detach(),'DCganOutput/fake_samples_epoch_%03d.png' % (epoch), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3935969-7a0b-4caa-8e78-684fde6d879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(counter_list, gen_loss_list, 'r.', label='Generator')\n",
    "plt.plot(counter_list, dis_loss_list, 'g.', label='Discriminator')\n",
    "plt.title(\"DCGAN Loss of Generator and Discriminator \")\n",
    "plt.xlabel(\"Batch Number\")\n",
    "plt.ylabel(\"Binary Cross Entropy Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f1f0e-d036-470b-b457-ae9b7d44fdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
